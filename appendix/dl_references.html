<!DOCTYPE html>
<html>

<head>
    <title>Deep learning references</title>
    <meta charset="UTF-8">
    <meta name="description" content="Deep learning references">
    <meta name="author" content="Thomio Watanabe">
    <link rel="stylesheet" type="text/css" href="../style/deeplibs.css">
</head>

<body>
<header>
    <a href="../index.html" style="color: white; font-size:20px;">
        <b style="display: inline-block; width: 768px">DeepLibs</b>
    </a>
</header>

<article>
<h1>Deep learning references</h1>

<p>
This section presents a timeline with the most important scientific papers for
 deep learning.<br>
To be fair, the papers must have more than 500 citations.<br>
The paper date is when it was first published.
</p>
<br>


<table id="refs" style="width:100%">
  <tr>
    <td valign="top">2016</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1612.08242">
        YOLO9000: Better, Faster, Stronger.
      </a>
      YOLOv2, faster (and hotter) CNN for object dection.
      [<a href="https://pjreddie.com/darknet/yolov2/">webpage</a>]
    </td>
  </tr>

  <tr>
    <td>2016</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1606.00915">
        DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution and Fully Connected CRFs.
      </a>
      DeepLab, CNN for semantic segmentation with atrous convolution.
    </td>
  </tr>

  <tr>
    <td>2016</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1603.05027">
        Identity Mappings in Deep Residual Networks.
      </a>
      ResNet v2.
    </td>
  </tr>

  <tr>
    <td valign="top">2016</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1602.07261">
        Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.
      </a>
      Google classification network. Inception v4 (Inception-ResNet).
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1512.03385">
        Deep residual learning for image recognition.
      </a>
      ResNet, introduced the residual connections.
    </td>
  </tr>

  <tr>
    <td valign="top">2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1512.02325">
        SSD: Single Shot MultiBox Detector
      </a>
      Single CNN for object dection.
      [<a href="https://github.com/weiliu89/caffe/tree/ssd">code</a>]
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1512.00567">
        Rethinking the Inception Architecture for Computer Vision.
      </a>
      Google classification network. Inception v2 and v3.
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1511.00561">
        SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation.
      </a>
      Encoder-decoder image segmentation network.
    </td>
  </tr>

  <tr>
    <td valign="top">2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1506.02640">
        You Only Look Once: Unified, Real-Time Object Detection.
      </a>
      Introduced the YOLO, fast (and hot) CNN for object dection.
      [<a href="https://pjreddie.com/darknet/yolov1/">webpage</a>]
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1506.01497">
        Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.
      </a>
      Region proposal based solution for object detection in images.
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://www.nature.com/articles/nature14539">
        Deep learning.
      </a>
      Survey-kind paper from big bosses.
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1504.08083">
        Fast R-CNN.
      </a>
      Region proposal based solution for object detection in images. Integrates a region proposal network and a classification network.
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">
        Fully Convolutional Networks for Semantic Segmentation.
      </a>
      FCN network for image segmentation. Introduced the deconvolution(transposed convolution)(or transposed correlation?).
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1502.03167">
        Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
      </a>
      One of the most important regularization techniques. BN-Inception.
    </td>
  </tr>

  <tr>
    <td>2015</td>
    <td>-</td>
    <td>
      <a href="https://www.nature.com/articles/nature14236">
        Human-level control through deep reinforcement learning.
      </a>
      Deep reinforcement learning to play Atari 2600 games in fancy journal.
    </td>
  </tr>

  <tr>
    <td>2014</td>
    <td>-</td>
    <td>
      <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets">
        Generative Adversarial Nets.
      </a>
      Introduced the generative adversarial networks.
    </td>
  </tr>

  <tr>
    <td>2014</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1409.4842">
        Going Deeper with Convolutions.
      </a>
      Google classification network. Inception v1 (GoogleNet).
    </td>
  </tr>

  <tr>
    <td>2014</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1409.1556">
         Very Deep Convolutional Networks for Large-Scale Image Recognition.
      </a>
      VGGNet, introduced the factored convolutions.
    </td>
  </tr>

  <tr>
    <td>2014</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1409.0575">
        ImageNet Large Scale Visual Recognition Challenge.
      </a>
      ImageNet paper describing the challenge and winner solutions.
    </td>
  </tr>

  <tr>
    <td>2014</td>
    <td>-</td>
    <td>
      <a href="http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf">
        Dropout: A Simple Way to Prevent Neural Networks from Overfitting.
      </a>
      Regularization technique.
    </td>
  </tr>

  <tr>
    <td>2013</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1312.6199">
        Intriguing properties of neural networks.
      </a>
      Introduced adversarial examples and perturbations.
    </td>
  </tr>

  <tr>
    <td>2013</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1312.5602">
        Playing Atari with Deep Reinforcement Learning.
      </a>
      Deep reinforcement learning to play Atari 2600 games. Introduced the DQN and experience replay.
    </td>
  </tr>

  <tr>
    <td>2013</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1312.4400">
        Network In Network.
      </a>
      NiN, introduced the 1x1 convolution.
    </td>
  </tr>

  <tr>
    <td>2013</td>
    <td>-</td>
    <td>
      <a href="https://arxiv.org/abs/1311.2524">
        Rich feature hierarchies for accurate object detection and semantic segmentation.
      </a>
      Region proposal based solution for object detection in images. Introduced the R-CNN.
    </td>
  </tr>

  <tr>
    <td>2012</td>
    <td>-</td>
    <td>
      <a href="https://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">
        ImageNet Classification with Deep Convolutional neural networks.
      </a>
      This paper presents the famous AlexNet network, winner of the 2012 Imagenet challenge (ILSVRC2012).
    </td>
  </tr>

  <tr>
    <td>2009</td>
    <td>-</td>
    <td>
      <a href="http://www.nowpublishers.com/article/DownloadSummary/MAL-006">
        Learning deep architectures for AI.
      </a>
      Review on deep architecture models.
    </td>
  </tr>

  <tr>
    <td>1998</td>
    <td>-</td>
    <td>
      <a href="http://www.dengfanxin.cn/wp-content/uploads/2016/03/1998Lecun.pdf">
        Gradient-based learning applied to document recognition.
      </a>
      Convolutional neural networks for handwriting recognition.
    </td>
  </tr>
</table>




</article>

<footer>
    <br>
    <div style="display: inline-block; width: 768px">
        Copyright &copy; <a href="https://thomio-watanabe.github.io">Thomio Watanabe</a>
    </div>
</footer>

</body>

</html>
